{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name - Shree Bohara, Github Username - ShreeBohara, USC id: 9969390417\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import bootstrap\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a\n",
    "Data Downloaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_path = \"../data/AReM\"\n",
    "\n",
    "test_data = []\n",
    "train_data = []\n",
    "\n",
    "for activity in os.listdir(base_path):\n",
    "    activity_path = os.path.join(base_path, activity)\n",
    "    if os.path.isdir(activity_path):\n",
    "        files = sorted(os.listdir(activity_path))\n",
    "        \n",
    "        for idx, filename in enumerate(files):\n",
    "            file_path = os.path.join(activity_path, filename)\n",
    "            \n",
    "\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                comment=\"#\",            # lines starting with '#' are treated as comments\n",
    "                header=None,            # no header in the data lines\n",
    "                names=[\"time\", \"avg_rss12\", \"var_rss12\",\n",
    "                       \"avg_rss13\", \"var_rss13\", \"avg_rss23\", \"var_rss23\"],\n",
    "                sep=\",\",                \n",
    "                skip_blank_lines=True,   \n",
    "                on_bad_lines=\"skip\",    \n",
    "                engine=\"python\"         \n",
    "            )\n",
    "\n",
    "            df.insert(0, \"activity\", activity)\n",
    "            \n",
    "            if activity in [\"bending1\", \"bending2\"]:\n",
    "                if idx < 2:\n",
    "                    test_data.append(df)\n",
    "                else:\n",
    "                    train_data.append(df)\n",
    "            else:\n",
    "                if idx < 3:\n",
    "                    test_data.append(df)\n",
    "                else:\n",
    "                    train_data.append(df)\n",
    "\n",
    "# Combine all the DataFrames\n",
    "testdf = pd.concat(test_data, ignore_index=True)\n",
    "traindf = pd.concat(train_data, ignore_index=True)\n",
    "\n",
    "# Export to CSV\n",
    "testdf.to_csv(\"test_data.csv\", index=False)\n",
    "traindf.to_csv(\"train_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9120 entries, 0 to 9119\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   activity   9120 non-null   object \n",
      " 1   time       9120 non-null   int64  \n",
      " 2   avg_rss12  9120 non-null   float64\n",
      " 3   var_rss12  9120 non-null   float64\n",
      " 4   avg_rss13  9120 non-null   float64\n",
      " 5   var_rss13  9120 non-null   float64\n",
      " 6   avg_rss23  9120 non-null   float64\n",
      " 7   var_rss23  9120 non-null   float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 570.1+ KB\n",
      "Train DataFrame info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33117 entries, 0 to 33116\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   activity   33117 non-null  object \n",
      " 1   time       33117 non-null  int64  \n",
      " 2   avg_rss12  33117 non-null  float64\n",
      " 3   var_rss12  33117 non-null  float64\n",
      " 4   avg_rss13  33117 non-null  float64\n",
      " 5   var_rss13  33117 non-null  float64\n",
      " 6   avg_rss23  33117 non-null  float64\n",
      " 7   var_rss23  33117 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(1)\n",
      "memory usage: 2.0+ MB\n",
      "Test DataFrame shape: (9120, 8)\n",
      "Train DataFrame shape: (33117, 8)\n",
      "Test DataFrame head:\n",
      "   activity  time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
      "0  bending1     0      39.25       0.43      22.75       0.43      33.75   \n",
      "1  bending1   250      39.25       0.43      23.00       0.00      33.00   \n",
      "2  bending1   500      39.25       0.43      23.25       0.43      33.00   \n",
      "3  bending1   750      39.50       0.50      23.00       0.71      33.00   \n",
      "4  bending1  1000      39.50       0.50      24.00       0.00      33.00   \n",
      "\n",
      "   var_rss23  \n",
      "0        1.3  \n",
      "1        0.0  \n",
      "2        0.0  \n",
      "3        0.0  \n",
      "4        0.0  \n",
      "Train DataFrame head:\n",
      "   activity  time  avg_rss12  var_rss12  avg_rss13  var_rss13  avg_rss23  \\\n",
      "0  bending1     0      42.00       0.71      21.25       0.43      30.00   \n",
      "1  bending1   250      41.50       0.50      20.25       1.48      31.25   \n",
      "2  bending1   500      41.50       0.50      14.25       1.92      33.00   \n",
      "3  bending1   750      40.75       0.83      15.75       0.43      33.00   \n",
      "4  bending1  1000      40.00       0.71      20.00       2.74      32.75   \n",
      "\n",
      "   var_rss23  \n",
      "0       0.00  \n",
      "1       1.09  \n",
      "2       0.00  \n",
      "3       0.00  \n",
      "4       0.43  \n"
     ]
    }
   ],
   "source": [
    "print(\"Test DataFrame info:\")\n",
    "testdf.info()\n",
    "\n",
    "print(\"Train DataFrame info:\")\n",
    "traindf.info()\n",
    "\n",
    "\n",
    "print(\"Test DataFrame shape:\", testdf.shape)\n",
    "print(\"Train DataFrame shape:\", traindf.shape)\n",
    "\n",
    "\n",
    "print(\"Test DataFrame head:\")\n",
    "print(testdf.head())\n",
    "\n",
    "print(\"Train DataFrame head:\")\n",
    "print(traindf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-domain features commonly used in time series classification include:\n",
    "\n",
    "Mean,\n",
    "Median,\n",
    "Variance,\n",
    "Standard deviation,\n",
    "Minimum,\n",
    "Maximum,\n",
    "Range,\n",
    "First quartile,\n",
    "Third quartile,\n",
    "Zero-crossings,\n",
    "Skewness,\n",
    "Kurtosis,\n",
    "Energy,\n",
    "Entropy,\n",
    "Autocorrelation,\n",
    "Trend,\n",
    "Seasonality,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Instance  min_1  max_1     mean_1  median_1     std_1  1st_quart_1  \\\n",
      "0          1  37.25  45.00  40.624792    40.500  1.475428        39.25   \n",
      "1          2  38.00  45.67  42.812812    42.500  1.434054        42.00   \n",
      "2          3  35.00  47.40  43.954500    44.330  1.557210        43.00   \n",
      "3          4  33.00  47.75  42.179812    43.500  3.666840        39.15   \n",
      "4          5  33.00  45.75  41.678063    41.750  2.241152        41.33   \n",
      "..       ...    ...    ...        ...       ...       ...          ...   \n",
      "83        84  20.75  46.25  34.763333    35.290  4.737266        31.67   \n",
      "84        85  21.50  51.00  34.935812    35.500  4.641102        32.00   \n",
      "85        86  18.33  47.67  34.333042    34.750  4.943612        31.25   \n",
      "86        87  18.33  45.75  34.599875    35.125  4.726858        31.50   \n",
      "87        88  15.50  43.67  34.225875    34.750  4.437168        31.25   \n",
      "\n",
      "    3rd_quart_1  min_2  max_2  ...     std_5  1st_quart_5  3rd_quart_5  min_6  \\\n",
      "0       42.0000    0.0   1.30  ...  2.186168      33.0000        36.00    0.0   \n",
      "1       43.6700    0.0   1.22  ...  1.993175      32.0000        34.50    0.0   \n",
      "2       45.0000    0.0   1.70  ...  1.997520      35.3625        36.50    0.0   \n",
      "3       45.0000    0.0   3.00  ...  3.845436      30.4575        36.33    0.0   \n",
      "4       42.7500    0.0   2.83  ...  2.408514      28.4575        31.25    0.0   \n",
      "..          ...    ...    ...  ...       ...          ...          ...    ...   \n",
      "83      38.2500    0.0  12.68  ...  3.171372      14.2500        18.33    0.0   \n",
      "84      38.0625    0.0  12.21  ...  3.188731      14.2375        18.25    0.0   \n",
      "85      38.0000    0.0  12.48  ...  2.997366      13.7500        18.00    0.0   \n",
      "86      38.0000    0.0  15.37  ...  2.902659      14.0000        18.25    0.0   \n",
      "87      37.2500    0.0  17.24  ...  2.989801      14.3300        18.25    0.0   \n",
      "\n",
      "    max_6    mean_6  median_6     std_6  1st_quart_6  3rd_quart_6  \n",
      "0    1.92  0.570583     0.430  0.582308         0.00       1.3000  \n",
      "1    3.11  0.571083     0.430  0.600383         0.00       1.3000  \n",
      "2    1.79  0.493292     0.430  0.512971         0.00       0.9400  \n",
      "3    2.18  0.613521     0.500  0.523771         0.00       1.0000  \n",
      "4    1.79  0.383292     0.430  0.388759         0.00       0.5000  \n",
      "..    ...       ...       ...       ...          ...          ...  \n",
      "83   9.39  3.288271     3.270  1.645811         2.05       4.3050  \n",
      "84  10.21  3.280021     3.015  1.699145         2.12       4.5000  \n",
      "85   8.01  3.261583     2.980  1.615604         2.05       4.3200  \n",
      "86   8.86  3.289542     3.015  1.678418         2.12       4.2600  \n",
      "87   9.42  3.479542     3.270  1.759311         2.24       4.5375  \n",
      "\n",
      "[88 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "time_series = ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "\n",
    "correct_columns = ['time', 'avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "\n",
    "all_features = []\n",
    "\n",
    "instance_number = 1\n",
    "for activity in sorted(os.listdir(base_path)):\n",
    "    activity_dir = os.path.join(base_path, activity)\n",
    "    if os.path.isdir(activity_dir):\n",
    "        \n",
    "        for file_name in sorted(os.listdir(activity_dir)):\n",
    "            if file_name.endswith('.csv'):\n",
    "                file_path = os.path.join(activity_dir, file_name)\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, skiprows=5, header=None, on_bad_lines='skip')\n",
    "                    df.columns = correct_columns\n",
    "                    instance_features = []\n",
    "                    instance_features.append(instance_number)\n",
    "                    \n",
    "                    for col in time_series:\n",
    "                        series = df[col]\n",
    "                        instance_features.extend([\n",
    "                            np.min(series),\n",
    "                            np.max(series),\n",
    "                            np.mean(series),\n",
    "                            np.median(series),\n",
    "                            np.std(series),\n",
    "                            np.percentile(series, 25),  \n",
    "                            np.percentile(series, 75)   \n",
    "                        ])\n",
    "                    \n",
    "                  \n",
    "                    all_features.append(instance_features)\n",
    "                    \n",
    "                   \n",
    "                    instance_number += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing file: {file_name} in {activity} folder. Error: {e}\")\n",
    "\n",
    "columns = ['Instance']  \n",
    "for i in range(1, 7):\n",
    "    columns.extend([\n",
    "        f'min_{i}', f'max_{i}', f'mean_{i}', f'median_{i}', \n",
    "        f'std_{i}', f'1st_quart_{i}', f'3rd_quart_{i}'\n",
    "    ])\n",
    "\n",
    "features_df = pd.DataFrame(all_features, columns=columns)\n",
    "\n",
    "print(features_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scipy/stats/_resampling.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  a_hat = 1/6 * sum(nums) / sum(dens)**(3/2)\n",
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/scipy/stats/_resampling.py:97: DegenerateDataWarning: The BCa confidence interval cannot be calculated. This problem is known to occur when the distribution is degenerate or the statistic is np.min.\n",
      "  warnings.warn(DegenerateDataWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviations and 90% Confidence Intervals:\n",
      "        Feature   Std Dev  Lower Bound  Upper Bound\n",
      "0         min_1  9.569975     8.488907    11.133816\n",
      "1         max_1  4.394362     3.507361     5.479474\n",
      "2        mean_1  5.335700     4.801922     5.982299\n",
      "3      median_1  5.440054     4.881402     6.105590\n",
      "4         std_1  1.770338     1.604359     1.988957\n",
      "5   1st_quart_1  6.153874     5.641103     6.735184\n",
      "6   3rd_quart_1  5.138925     4.438049     5.968769\n",
      "7         min_2  0.000000          NaN          NaN\n",
      "8         max_2  5.062729     4.682200     5.448451\n",
      "9        mean_2  1.574198     1.410577     1.708444\n",
      "10     median_2  1.412293     1.251581     1.550553\n",
      "11        std_2  0.883215     0.806956     0.941281\n",
      "12  1st_quart_2  0.946386     0.840519     1.041329\n",
      "13  3rd_quart_2  2.125399     1.902557     2.298213\n",
      "14        min_3  2.956462     2.784111     3.129535\n",
      "15        max_3  4.875137     4.261770     5.543800\n",
      "16       mean_3  4.008228     3.480724     4.540221\n",
      "17     median_3  4.036396     3.490727     4.596862\n",
      "18        std_3  0.945683     0.802282     1.203390\n",
      "19  1st_quart_3  4.220658     3.695104     4.749790\n",
      "20  3rd_quart_3  4.171628     3.613252     4.751726\n",
      "21        min_4  0.000000          NaN          NaN\n",
      "22        max_4  2.183625     1.996524     2.391778\n",
      "23       mean_4  1.166178     1.076846     1.219203\n",
      "24     median_4  1.145985     1.055675     1.198464\n",
      "25        std_4  0.457805     0.423323     0.486637\n",
      "26  1st_quart_4  0.843405     0.777697     0.890273\n",
      "27  3rd_quart_4  1.552504     1.433158     1.622263\n",
      "28        min_5  6.124001     4.749096     7.848983\n",
      "29        max_5  5.741238     4.853804     6.697800\n",
      "30       mean_5  5.675543     4.618871     6.919405\n",
      "31     median_5  5.813782     4.749262     7.131217\n",
      "32        std_5  1.023850     0.862497     1.290783\n",
      "33  1st_quart_5  6.096465     5.040286     7.459130\n",
      "34  3rd_quart_5  5.531720     4.556700     6.732250\n",
      "35        min_6  0.045838     0.000000     0.099543\n",
      "36        max_6  2.518921     2.296481     2.834233\n",
      "37       mean_6  1.154889     1.064353     1.213275\n",
      "38     median_6  1.086474     1.001578     1.146468\n",
      "39        std_6  0.517112     0.481060     0.544787\n",
      "40  1st_quart_6  0.758687     0.693743     0.807509\n",
      "41  3rd_quart_6  1.523739     1.405539     1.597729\n"
     ]
    }
   ],
   "source": [
    "\n",
    "std_devs = features_df.iloc[:, 1:].std()\n",
    "\n",
    "\n",
    "def calc_std(data, axis=-1):\n",
    "    return np.std(data, axis=axis)\n",
    "\n",
    "\n",
    "bootstrap_intervals = {}\n",
    "\n",
    "for col in features_df.columns[1:]:  # Skip the 'Instance' column\n",
    "    data = features_df[col].values\n",
    "    res = bootstrap((data,), calc_std, vectorized=True, confidence_level=0.90, n_resamples=10000)\n",
    "    bootstrap_intervals[col] = (res.confidence_interval.low, res.confidence_interval.high)\n",
    "\n",
    "\n",
    "std_df = pd.DataFrame({\n",
    "    'Feature': features_df.columns[1:],\n",
    "    'Std Dev': std_devs.values,\n",
    "    'Lower Bound': [interval[0] for interval in bootstrap_intervals.values()],\n",
    "    'Upper Bound': [interval[1] for interval in bootstrap_intervals.values()]\n",
    "})\n",
    "\n",
    "print(\"Standard Deviations and 90% Confidence Intervals:\")\n",
    "print(std_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Mean: Captures the central tendency, giving an overall measure of the activity level.\n",
    "\n",
    "Standard Deviation: Captures variability, distinguishing activities with different levels of consistency.\n",
    "\n",
    "Maximum: Captures the peak value, indicating the highest intensity of the activity.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a\n",
    "The linear model is the correct model.\n",
    "The cubic model has extra terms (𝑋2 and  𝑋3) that are not needed.\n",
    "\n",
    "A model with more terms can always fit the training data as well as or better than a simpler model.\n",
    "\n",
    "So, the cubic model will have a lower or equal training RSS compared to the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b\n",
    "The linear model is the right model and should work well on new (test) data.\n",
    "\n",
    "The cubic model might fit the training data too closely, even capturing random noise.\n",
    "\n",
    "This makes it worse at predicting new data (overfitting).\n",
    "So, the cubic model will likely have a higher test RSS than the linear model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c\n",
    "The linear model is too simple and cannot capture the full pattern in the data.\n",
    "\n",
    "The cubic model has more flexibility to fit the data better.\n",
    "More flexibility means a better fit on training data.\n",
    "\n",
    "So, the cubic model will have a lower or equal training RSS compared to the linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d\n",
    "If the true relationship is only slightly non-linear, the cubic model may overfit and do worse on test data.\n",
    "\n",
    "If the true relationship is very non-linear, the cubic model might be a better choice and predict new data more accurately.\n",
    "\n",
    "So, the test RSS for the cubic model could be lower or higher than the linear model, depending on how much non-linearity is present."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "https://dganesan.github.io/mhealth-course/chapter3-activityrecognition/ch3-time-domain-features.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
